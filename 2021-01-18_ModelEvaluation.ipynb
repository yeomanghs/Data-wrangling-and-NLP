{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy, re\n",
    "from spacy.attrs import ENT_IOB\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from spacy import displacy\n",
    "from spacy.pipeline import EntityRuler\n",
    "from spacy.symbols import ORTH,LEMMA,POS\n",
    "from pathlib import Path\n",
    "from spacy.tokens import Span\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.en import English\n",
    "from spacy.strings import StringStore\n",
    "import json\n",
    "from collections import Counter\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import training data\n",
    "recordDictBack = []\n",
    "jsonFile = \"D:\\\\Users\\\\figohjs\\\\Documents\\\\NLP\\\\NER\\\\data\\\\training\\\\2020-12-04_LablledStr.json\"\n",
    "\n",
    "with open(jsonFile, 'r', encoding='utf-8') as input_file:\n",
    "    for row in input_file.readlines():\n",
    "        recordDictBack.append(json.loads(row))\n",
    "\n",
    "#all desc\n",
    "descList = [i['content'] for i in recordDictBack]\n",
    "\n",
    "#all tag\n",
    "tagList = [i['tagList'] for i in recordDictBack]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from yan ling - extra 200 rows\n",
    "yanLingJsonFolder = \"D:\\\\Users\\\\figohjs\\\\Documents\\\\NLP\\\\NER\\\\data\\\\training\\\\Labelled_200_20201110\"\n",
    "\n",
    "yanLingRecord = []\n",
    "for yanLingFile in os.listdir(yanLingJsonFolder):\n",
    "    with open(yanLingJsonFolder + '\\\\' + yanLingFile) as input_file:\n",
    "        for row in input_file.readlines():\n",
    "            yanLingRecord.append(json.loads(row))    \n",
    "\n",
    "yanLingFinalRecord = cleanRecord(yanLingRecord)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### munirah's processing pipeline and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_case_gen_pattern(parsed_doc):\n",
    "    strg_2=''\n",
    "    passport=False\n",
    "    \n",
    "    #   Change format of capitalized words into proper case (specifically nouns: NNP, NNS, NNPS) \n",
    "    for token in parsed_doc:\n",
    "        tagged_sent = [(token.text, token.tag_)]\n",
    "        \n",
    "        normalized_sent = [w.capitalize() if (t in [\"NNP\",\"NNS\",\"NNPS\"] and w.isupper()) else w for (w,t) in tagged_sent]\n",
    "        strg = re.sub(\" (?=[\\.,'!?:;])\", \"\", ' '.join(normalized_sent))   \n",
    "\n",
    "        lowerList = ('name','cash','bank','inter','amlatfa','cdd','jalan','ic','cust','business','director', 'sole', 'proprietor','str', 'cdm','saving', 'rm', 'myr','place','branch')\n",
    "\n",
    "        if any(substring in strg.lower() for substring in lowerList):\n",
    "               strg=strg.lower()\n",
    "                \n",
    "        # convert the remaining uppercase to lowercase\n",
    "        if strg.isupper():\n",
    "            strg = strg.lower()\n",
    "        \n",
    "        # remove unnecessary punctuations \n",
    "        strg_2 += re.sub(r'[=*()]',r'',strg.strip())\n",
    "        strg_2 += ' '\n",
    "        \n",
    "            \n",
    "\n",
    "    # remove space before certain symbols like <space><.> or <space><,>\n",
    "    strg_2=re.sub(r'\\s+([?.!,:\"/\\'])', r'\\1', strg_2)\n",
    "    strg_2=strg_2.replace(\"Õ\",\" \").replace(\"ð\",\" \").replace(\"õ\",\" \")\n",
    "    strg_2=strg_2.replace(\"  \",\". \")\n",
    "     # remove space after certain symbols like <space><.> or <space><,>\n",
    "    strg_2=re.sub(r'([?/])+\\s', r'\\1', strg_2)\n",
    "    strg_2=strg_2.replace('\"','\\\\\"')\n",
    "    \n",
    "    if(strg_2.lower().__contains__('passport')):\n",
    "        passport=True\n",
    "    phrase_matcher(strg_2, passport)\n",
    "    \n",
    "#     print ('\\n')\n",
    "    \n",
    "    return strg_2.strip()\n",
    "\n",
    "\n",
    "# phrase matcher: shape\n",
    "def phrase_matcher(strg, p_e):\n",
    "    nlp = English()\n",
    "    \n",
    "    matcher = PhraseMatcher(nlp.vocab, attr=\"SHAPE\")\n",
    "    matcher.add(u\"STR_ID\", None, nlp(u\"aa/025/s/2016/000019\"), nlp(u\"aa/025/s/2016/000075\"))\n",
    "    matcher.add(u\"PERSON_ID\", None, nlp(u\"881102-08-5192\"))\n",
    "#     matcher.add(u\"PERSON_ID_2\", None, nlp(u\"661124085949\"), nlp(u\"710905125067\"))\n",
    "    matcher.add(u\"PASSPORT\", None, nlp(u\"r711493\"), nlp(u\"ma438972\"), nlp(u\"a3894268\"))\n",
    "    matcher.add(u\"PASSPORT_OR_NRIC\", None, nlp(u\"706251339\"), nlp(u\"720201106027\"), nlp(u\"nric: 811018105265\"), nlp(u\"710905125067\"))\n",
    "    stringstore = StringStore([u\"STR_ID\",u\"PERSON_ID\",u\"PASSPORT\",u\"PASSPORT_OR_NRIC\"])\n",
    "    \n",
    "#     doc = nlp(strg.lower())\n",
    "#     for match_id, start, end in matcher(doc):\n",
    "#         span = doc[start:end]\n",
    "#     #         with open(\"D:\\\\Users\\\\mcazwan\\\\Desktop\\\\fisitti\\\\str-id-patterns.jsonl\", \"a\") as text_file:\n",
    "#     #             text_file.write('{\\n\"label\": \"STR_ID\", [{\"TEXT\":' + span.text + '}]),\\n')\n",
    "        \n",
    "#         #  only allow 12 characters for person_id\n",
    "#         if match_id == stringstore[u\"PERSON_ID\"] or match_id == stringstore[u\"PERSON_ID_2\"]:\n",
    "#             if(len(span.text.replace(' ','').replace('-','')) == 12):\n",
    "#                 print(\"(person_id):\", doc[start:end])\n",
    "#         elif match_id == stringstore[u\"PASSPORT\"] and p_e == True:\n",
    "#         # check pattern\n",
    "#             if(7 <= len(span.text.replace(' ','').replace('-','')) <= 9):\n",
    "#                 print(\"(passport):\", doc[start:end])\n",
    "#         elif match_id == stringstore[u\"PASSPORT_OR_NRIC\"]:\n",
    "#             if(7 <= len(span.text.replace(' ','').replace('-','')) <= 9) and p_e == True:\n",
    "#                 print(\"(passport-digit):\", doc[start:end])\n",
    "                \n",
    "#             elif(len(span.text.replace(' ','').replace('-','')) == 12):\n",
    "#                 ic=span.text.replace(' ','').replace('-','')\n",
    "#                 if(int(ic[2:4]) <= 12 and int(ic[4:6]) <= 31 and int(ic[6:8]) <= 14):\n",
    "#                     print(\"(nric-digit):\", doc[start:end])\n",
    "#         elif match_id == stringstore[u\"STR_ID\"]:\n",
    "#             print(\"(str_id):\", doc[start:end])\n",
    "             \n",
    "\n",
    "# fix spaces\n",
    "def fix_space_tags(doc):\n",
    "    ent_iobs = doc.to_array([ENT_IOB])\n",
    "    for i, token in enumerate(doc):\n",
    "        if token.is_space:\n",
    "            # Sets 'O' tag (0 is None, so I is 1, O is 2)\n",
    "            ent_iobs[i] = 2\n",
    "    \n",
    "    doc.from_array([ENT_IOB], ent_iobs.reshape((len(doc), 1)))\n",
    "    return doc\n",
    "\n",
    "def prevent_sentence_boundaries(doc):\n",
    "    for token in doc:\n",
    "        if not can_be_sentence_start(token):\n",
    "            token.is_sent_start = False\n",
    "    return doc\n",
    "\n",
    "\n",
    "def can_be_sentence_start(token):\n",
    "#     print(token.text,':',token.i,'\\n')\n",
    "#     create separator\n",
    "    \n",
    "    if token.i == 0:\n",
    "        return True\n",
    "    # We're not checking for is_title here to ignore arbitrary titlecased\n",
    "    # tokens within sentences\n",
    "    \n",
    "    elif token.nbor(-1).is_punct and token.nbor(-1).text not in [':','/','-']:\n",
    "        return True\n",
    "\n",
    "    elif token.nbor(-1).is_space:\n",
    "        return True\n",
    "    \n",
    "    else:\n",
    "        return False\n",
    "\n",
    "spacyModel = 'en_core_web_md'\n",
    "nlp = spacy.load(spacyModel, disable=['ner'])\n",
    "nlp.add_pipe(prevent_sentence_boundaries, before=\"parser\")\n",
    "\n",
    "#     for other processing   \n",
    "munirahModel = 'D:\\\\Users\\\\figohjs\\\\Documents\\\\NLP\\\\Spacy\\\\NER\\\\trained-model\\\\NER_All_Labels_lg'\n",
    "nlp2 = spacy.load(munirahModel)\n",
    "nlp2.add_pipe(fix_space_tags, name=\"fix-ner\", before=\"ner\")\n",
    "nlp2.add_pipe(prevent_sentence_boundaries, before=\"parser\")\n",
    "\n",
    "jsonlFile = \"D:\\\\Users\\\\figohjs\\\\Documents\\\\NLP\\\\NER\\\\Notebook\\\\patterns.jsonl\"\n",
    "new_ruler = EntityRuler(nlp).from_disk(jsonlFile)\n",
    "nlp2.add_pipe(new_ruler, after='ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagList[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descList[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction\n",
    "doc = nlp.pipe(iter(descList), batch_size=10, n_threads=4000) \n",
    "\n",
    "result = []\n",
    "for parsed_doc in doc:\n",
    "    #  add pipe\n",
    "#     doc_2 = nlp2(change_case(parsed_doc))\n",
    "    doc_2 = nlp2(change_case_gen_pattern(parsed_doc))\n",
    "    result.append(doc_2)\n",
    "\n",
    "predResultMunirah = []\n",
    "for record in result:\n",
    "    tempList = []\n",
    "    for entity in record.ents:\n",
    "        if entity.label_ in ['PERSON', 'ORG']:\n",
    "            tempList.append((entity, entity.label_))\n",
    "    predResultMunirah.append(tempList)\n",
    "\n",
    "#convert result and tag into str for saving purpose\n",
    "predResultMunirah2 = [[(str(j[0]),str(j[1])) for j in i] for i in predResultMunirah]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert prediction, real result and desc into dict for file saving purpose\n",
    "dfTag = pd.DataFrame()\n",
    "dfTag['Description'] = descList\n",
    "dfTag['RealTag'] = tagList\n",
    "dfTag['PredTagMunirah'] = predResultMunirah2\n",
    "recordDict = dfTag.to_dict(orient = 'record')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(recordDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing list of dicts in a json file\n",
    "jsonFile = \"D:\\\\Users\\\\figohjs\\\\Documents\\\\NLP\\\\NER\\\\data\\\\training\\\\2020-12-09_MunirahPrediction614.json\"\n",
    "\n",
    "with open(jsonFile, 'w', encoding='utf-8') as output_file:\n",
    "    for dic in recordDict:\n",
    "        json.dump(dic, output_file) \n",
    "        output_file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trained with external data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Script.crfProcessing import *\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import training data\n",
    "recordDictBack = []\n",
    "jsonFile = \"D:\\\\Users\\\\figohjs\\\\Documents\\\\NLP\\\\NER\\\\data\\\\training\\\\2020-12-04_LablledStr.json\"\n",
    "\n",
    "with open(jsonFile, 'r', encoding='utf-8') as input_file:\n",
    "    for row in input_file.readlines():\n",
    "        recordDictBack.append(json.loads(row))\n",
    "\n",
    "#all desc\n",
    "descList = [i['content'] for i in recordDictBack]\n",
    "\n",
    "#all tag\n",
    "tagList = [i['tagList'] for i in recordDictBack]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model in pickle format\n",
    "# filename = 'D:/Users/figohjs/Documents/NLP/NER/Model/2020-11-09_CRFmodel.sav'\n",
    "filename = 'D:/Users/figohjs/Documents/NLP/NER/Model/2020-01-14_CRFmodel_Externalv1.sav'\n",
    "loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "predResultCRF = []\n",
    "#loop every desc:\n",
    "for no, desc in enumerate(descList):\n",
    "    try:\n",
    "        #processing\n",
    "        cleanDesc = cleanText(desc)\n",
    "        cleanDesc = changeCase(cleanDesc)\n",
    "        cleanDesc = changeCase2(cleanDesc)\n",
    "        cleanDesc = changeCase3(cleanDesc)\n",
    "        #features engineering\n",
    "        desc2 = [(i,) for i in cleanDesc.split(' ')]\n",
    "        descFeatures = [sent2features(i) for i in [desc2]]\n",
    "        #prediction\n",
    "        y_pred = loaded_model.predict(descFeatures)\n",
    "        #further processing\n",
    "        predList = getNamedEntity(y_pred, [cleanDesc.split(' ')])[0]\n",
    "        predResultCRF.append(predList)\n",
    "    except Exception as e:\n",
    "        print(e )\n",
    "        print('\\n')\n",
    "        print('Description no:%s'%str(no))\n",
    "        print('\\n')\n",
    "        print(desc)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert prediction, real result and desc into dict for file saving purpose\n",
    "dfTag = pd.DataFrame()\n",
    "dfTag['Description'] = descList\n",
    "dfTag['RealTag'] = tagList\n",
    "dfTag['PredTagCRF'] = predResultCRF\n",
    "recordDict = dfTag.to_dict(orient = 'record')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing list of dicts in a json file\n",
    "# jsonFile = \"D:\\\\Users\\\\figohjs\\\\Documents\\\\NLP\\\\NER\\\\data\\\\training\\\\2020-12-17_CRFPrediction614.json\"\n",
    "jsonFile = \"D:\\\\Users\\\\figohjs\\\\Documents\\\\NLP\\\\NER\\\\data\\\\training\\\\2021-01-14_CRFPrediction614.json\"\n",
    "\n",
    "with open(jsonFile, 'w', encoding='utf-8') as output_file:\n",
    "    for dic in recordDict:\n",
    "        json.dump(dic, output_file) \n",
    "        output_file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trained with internal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default features used in nltk\n",
    "def word2features(sent, i):\n",
    "    word = str(sent[i][0])\n",
    "#     postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "#         'ori':word,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "#         'postag': postag,\n",
    "#         'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = str(sent[i-1][0])\n",
    "#         postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "#             '-1:postag': postag1,\n",
    "#             '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        #beginning of speech\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = str(sent[i+1][0])\n",
    "#         postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "#             '+1:postag': postag1,\n",
    "#             '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        #end of speech\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, label in sent]\n",
    "\n",
    "def generateFeatures(descList):\n",
    "    featuresList = []\n",
    "    \n",
    "    for desc in descList: \n",
    "        sample = [(i,) for i in desc.split(' ')]\n",
    "        sampleFeatures = [sent2features(i) for i in [sample]]\n",
    "        featuresList.append(sampleFeatures[0])\n",
    "    \n",
    "    return featuresList\n",
    "\n",
    "# This is a class te get sentence. The each sentence will be list of tuples with its tag and pos.\n",
    "class sentence(object):\n",
    "    def __init__(self, df):\n",
    "        self.n_sent = 1\n",
    "        self.df = df\n",
    "        self.empty = False\n",
    "        agg = lambda s : [(w, t) for w, t in zip(s['Token'].values.tolist(),\n",
    "                                                s['Tag'].values.tolist())]\n",
    "        self.grouped = self.df.groupby(\"Sentence\").apply(agg)\n",
    "        self.sentences = [s for s in self.grouped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'D:/Users/figohjs/Documents/NLP/NER/Model/2021-01-14_CRFmodel_Internalv1.sav'\n",
    "loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from yan ling - extra 200 rows\n",
    "yanLingJsonFolder = \"D:\\\\Users\\\\figohjs\\\\Documents\\\\NLP\\\\NER\\\\data\\\\training\\\\Labelled_200_20201110\"\n",
    "\n",
    "yanLingRecord = []\n",
    "for yanLingFile in os.listdir(yanLingJsonFolder):\n",
    "    with open(yanLingJsonFolder + '\\\\' + yanLingFile) as input_file:\n",
    "        for row in input_file.readlines():\n",
    "            yanLingRecord.append(json.loads(row))    \n",
    "\n",
    "#json file from NER label app contains duplicated record coz it s saved time by time\n",
    "def cleanRecord(result): \n",
    "    finalList = []\n",
    "    \n",
    "    resultDict = [{i['content']:i['tagList'] for i in result}]\n",
    "    dictKeys = [key for i in resultDict for key,val in i.items()]\n",
    "    \n",
    "    for finalKey in set(dictKeys):\n",
    "        tempDict = {}\n",
    "        #take first entry of records with same content\n",
    "        tagVal = [val for i in resultDict for key, val in i.items() if key == finalKey][0]\n",
    "        contentVal = finalKey\n",
    "        tempDict['tagList'] = tagVal\n",
    "        tempDict['content'] = contentVal\n",
    "        finalList.append(tempDict)\n",
    "\n",
    "    return finalList\n",
    "            \n",
    "yanLingFinalRecord = cleanRecord(yanLingRecord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all desc\n",
    "descListYL = [i['content'] for i in yanLingFinalRecord]\n",
    "\n",
    "#all tag\n",
    "tagListYL = [i['tagList'] for i in yanLingFinalRecord]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import stopword\n",
    "stopWordList = []\n",
    "txtFile = \"D:\\\\Users\\\\figohjs\\\\Documents\\\\NLP\\\\NER\\\\Data\\\\training\\\\stopwords.txt\"\n",
    "with open(txtFile, 'r') as myfile:\n",
    "    for row in myfile.readlines():\n",
    "        stopWordList.append(re.sub('\\n','',row))\n",
    "\n",
    "#import surname\n",
    "surnameList = []\n",
    "txtFile = \"D:\\\\Users\\\\figohjs\\\\Documents\\\\NLP\\\\NER\\\\Data\\\\training\\\\surname.txt\"\n",
    "with open(txtFile, 'r') as myfile:\n",
    "    for row in myfile.readlines():\n",
    "        surnameList.append(re.sub('\\n','',row))\n",
    "\n",
    "#tag dictionary\n",
    "tagDict = {'org':'ORG', 'per':'PERSON', 'geo': 'GEO'}\n",
    "\n",
    "def getNamedEntity(records, text):\n",
    "    finalResult = []\n",
    "    for noRow, row in enumerate(records):\n",
    "        temp = []\n",
    "        for noTerm, term in enumerate(row):\n",
    "            #if token is beginning of org or per\n",
    "            if term in ['B-' + i for i in tagDict.keys()]:\n",
    "                tagType = term.split('-')[1]\n",
    "                namedEnt = text[noRow][noTerm]\n",
    "                #if current term is not the last term of the row\n",
    "                if (noTerm + 1) != len(row):\n",
    "                    if row[noTerm + 1] != ('I-' + tagType):\n",
    "                        tempResult = checkTuple((namedEnt, tagDict[tagType]))\n",
    "                        if tempResult:\n",
    "                            temp.append(tempResult)\n",
    "                            \n",
    "                else:\n",
    "                    tempResult = checkTuple((namedEnt, tagDict[tagType]))\n",
    "                    if tempResult:\n",
    "                        temp.append(tempResult)\n",
    "\n",
    "            #if token is inside org or per\n",
    "            elif term in ['I-org', 'I-per', 'I-geo']:\n",
    "                tagType = term.split('-')[1]\n",
    "                namedEnt = ' '.join([namedEnt, text[noRow][noTerm]])\n",
    "                #if current term is not the last term of the row\n",
    "                if (noTerm + 1) != len(row):\n",
    "                    if row[noTerm + 1] != ('I-' + tagType):\n",
    "                        tempResult = checkTuple((namedEnt, tagDict[tagType]))\n",
    "                        if tempResult:\n",
    "                            temp.append(tempResult)   \n",
    "\n",
    "                else:\n",
    "                    tempResult = checkTuple((namedEnt, tagDict[tagType]))\n",
    "                    if tempResult:\n",
    "                        temp.append(tempResult)\n",
    "                        \n",
    "        finalResult.append(temp)\n",
    "            \n",
    "    return finalResult  \n",
    "\n",
    "def checkTuple(tupleResult):\n",
    "    if tupleResult[1] in ['PERSON', 'GEO']:\n",
    "        if re.search('berhad|bhd', tupleResult[0], flags = re.I):\n",
    "            return (tupleResult[0], 'ORG')\n",
    "        else:\n",
    "            #filter out geo\n",
    "            if tupleResult[1] == 'GEO':\n",
    "                return None\n",
    "            else:\n",
    "                return tupleResult\n",
    "            \n",
    "    elif tupleResult[1] == 'ORG':\n",
    "        #put chinese name back as label\n",
    "        if len(tupleResult[0].split(' ')) == 3 and not re.search('berhad|bhd', tupleResult[0], flags = re.I):\n",
    "            if tupleResult[0].split(' ')[0].lower() in surnameList:\n",
    "                return (tupleResult[0], 'PERSON')\n",
    "            else:\n",
    "                return tupleResult\n",
    "        else:\n",
    "            return tupleResult\n",
    "    else:\n",
    "        return tupleResult\n",
    "\n",
    "#first layer of text cleaning\n",
    "def cleanText(text):\n",
    "    #special chars list\n",
    "    scList = ['\\si.e.\\s']\n",
    "    \n",
    "    #replace \\n with ' '\n",
    "    text = re.sub('\\n', ' ', text)\n",
    "    #remove null in end of sentence\n",
    "    text = re.sub('null $', '', text, flags = re.I)\n",
    "    #remove rm as training data does not have rm\n",
    "    text = re.sub('(rm|myr)\\s*(\\d+)', r'\\2', text, flags = re.I)\n",
    "    #remove special char \n",
    "    text = re.sub('|'.join(scList), '', text)\n",
    "    #remove additional spaces\n",
    "    text = re.sub('(\\s)+', r'\\1', text)        \n",
    "    return text\n",
    "\n",
    "predResultCRF = []\n",
    "#loop every desc:\n",
    "for no, desc in enumerate(descListYL):\n",
    "    try:\n",
    "        cleanDesc = cleanText(desc)\n",
    "        desc2 = [(i,) for i in cleanDesc.split(' ')]\n",
    "        descFeatures = [sent2features(i) for i in [desc2]]\n",
    "        y_pred = loaded_model.predict(descFeatures)\n",
    "        #further processing\n",
    "        predList = getNamedEntity(y_pred, [cleanDesc.split(' ')])[0]\n",
    "        predResultCRF.append(predList)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e )\n",
    "        print('\\n')\n",
    "        print('Description no:%s'%str(no))\n",
    "        print('\\n')\n",
    "        print(desc)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predResultCRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'descList' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-6472336cd7dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#convert prediction, real result and desc into dict for file saving purpose\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdfTag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdfTag\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Description'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdescList\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdfTag\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'RealTag'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtagList\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdfTag\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'PredTagCRF'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredResultCRF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'descList' is not defined"
     ]
    }
   ],
   "source": [
    "#convert prediction, real result and desc into dict for file saving purpose\n",
    "dfTag = pd.DataFrame()\n",
    "dfTag['Description'] = descList\n",
    "dfTag['RealTag'] = tagList\n",
    "dfTag['PredTagCRF'] = predResultCRF\n",
    "recordDict = dfTag.to_dict(orient = 'record')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load json data from munirah prediction file\n",
    "jsonFile = \"D:\\\\Users\\\\figohjs\\\\Documents\\\\NLP\\\\NER\\\\data\\\\training\\\\2020-12-09_MunirahPrediction614.json\"\n",
    "\n",
    "munirahList = []\n",
    "\n",
    "with open(jsonFile) as input_file:\n",
    "    for row in input_file.readlines():\n",
    "        munirahList.append(json.loads(row))   \n",
    "\n",
    "#extract munirah prediction\n",
    "predMunirahList = [i['PredTagMunirah'] for i in munirahList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load json data from munirah prediction file\n",
    "# jsonFile = \"D:\\\\Users\\\\figohjs\\\\Documents\\\\NLP\\\\NER\\\\data\\\\training\\\\2020-12-09_CRFPrediction614.json\"\n",
    "# jsonFile = \"D:\\\\Users\\\\figohjs\\\\Documents\\\\NLP\\\\NER\\\\data\\\\training\\\\2020-12-17_CRFPrediction614.json\"\n",
    "jsonFile = \"D:\\\\Users\\\\figohjs\\\\Documents\\\\NLP\\\\NER\\\\data\\\\training\\\\2021-01-14_CRFPrediction614.json\"\n",
    "\n",
    "crfList = []\n",
    "\n",
    "with open(jsonFile) as input_file:\n",
    "    for row in input_file.readlines():\n",
    "        crfList.append(json.loads(row))   \n",
    "\n",
    "#extract munirah prediction\n",
    "predCRFList = [i['PredTagCRF'] for i in crfList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert bank to org in real tag\n",
    "def changeBanktoOrg(result):\n",
    "    realTagList = []\n",
    "    for record in result:\n",
    "        tempList = []\n",
    "        for row in record['RealTag']:\n",
    "            if row[1] == 'BANK':\n",
    "                tempList.append([row[0], 'ORG', row[2]])\n",
    "            else:\n",
    "                tempList.append(row)\n",
    "        realTagList.append(tempList)\n",
    "    return realTagList\n",
    "\n",
    "def calculateResult(pred, real, categoryList):\n",
    "    finalResultList = []\n",
    "    for no, record in enumerate(pred):\n",
    "        resultDict = {}\n",
    "        for category in categoryList:\n",
    "            predList = [i for i in record if i[1] == category]\n",
    "            realList = [i for i in real[no] if i[1] == category]\n",
    "            #form dict for pred and real - groupby and count\n",
    "            #ex:{'Affin Hwang-PERSON': 2, 'Lay Hong Berhad-ORG': 2} for 1 record\n",
    "            predDict = dict(Counter([str(i[0]).lower() + '-' + i[1] for i in predList]))\n",
    "            realDict = dict(Counter([str(i[0]).lower() + '-' + i[1] for i in realList]))\n",
    "            numCorrect = sum([predDict[key] if predDict[key] <= realDict[key] else realDict[key]  \n",
    "                              for key in predDict.keys() if key in realDict.keys()])\n",
    "            totalEntity = sum([j for i,j in realDict.items()])\n",
    "            totalPred = sum([j for i,j in predDict.items()])\n",
    "            #total number of correct prediction, prediction and entities in real result by each category for each record\n",
    "            resultDict[category] = (numCorrect, totalPred, totalEntity)\n",
    "        \n",
    "        #correct named entities but wrong label\n",
    "        predList = [i[0] for i in record]\n",
    "        realList = [i[0] for i in real[no]]\n",
    "        predDict = dict(Counter([str(i[0]).lower() for i in predList]))\n",
    "        realDict = dict(Counter([str(i[0]).lower() for i in realList]))        \n",
    "        numCorrect = sum([predDict[key] if predDict[key] <= realDict[key] else realDict[key]  \n",
    "                          for key in predDict.keys() if key in realDict.keys()])\n",
    "        totalEntity = sum([j for i,j in realDict.items()])\n",
    "        totalPred = sum([j for i,j in predDict.items()])\n",
    "        #store result: number of correct named entities but wrong label\n",
    "        resultDict['NE'] = (numCorrect, totalPred, totalEntity)\n",
    "        \n",
    "        #store result for each record\n",
    "        finalResultList.append(resultDict)\n",
    "    return finalResultList\n",
    "\n",
    "def calculateEvalMetric(inputList, categoryList):\n",
    "    #total number of correct prediction, prediction and entities in real result by each category for each record\n",
    "    #input\n",
    "    #initiate a dict\n",
    "    resultDict = {}\n",
    "    metricList = ['fn', 'fp', 'tp', 'Precision', 'Recall', 'F1Score']\n",
    "    for category in categoryList:\n",
    "        resultDict[category] = {}\n",
    "        for metric in metricList:\n",
    "            resultDict[category][metric] = 0\n",
    "    \n",
    "    #get tp, fp and fn for each category\n",
    "    for record in inputList:\n",
    "        for category in categoryList:\n",
    "            resultDict[category]['tp']+=record[category][0]\n",
    "            resultDict[category]['fp']+=record[category][1]-record[category][0]\n",
    "            #if total of entities >= total prediction\n",
    "            if record[category][2] >= record[category][1]:\n",
    "                resultDict[category]['fn']+=record[category][2]-record[category][1]\n",
    "            else:\n",
    "                resultDict[category]['fn']+=0\n",
    "                \n",
    "    #get tp, fp and fn for all\n",
    "    totalFN = sum([j['fn'] for i,j in resultDict.items()])\n",
    "    totalFP = sum([j['fp'] for i,j in resultDict.items()])\n",
    "    totalTP = sum([j['tp'] for i,j in resultDict.items()]) \n",
    "    \n",
    "    allCategory = 'Overall'\n",
    "    resultDict[allCategory] = {}\n",
    "    resultDict[allCategory]['fn'] = totalFN \n",
    "    resultDict[allCategory]['fp'] = totalFP\n",
    "    resultDict[allCategory]['tp'] = totalTP \n",
    "          \n",
    "    #calculate precision, recall and f1score for each category and all\n",
    "    for category in categoryList + [allCategory]:\n",
    "        resultDict[category]['Precision'] = resultDict[category]['tp']/(resultDict[category]['tp'] + resultDict[category]['fp'])\n",
    "        resultDict[category]['Recall'] = resultDict[category]['tp']/(resultDict[category]['tp'] + resultDict[category]['fn'])\n",
    "        resultDict[category]['F1Score'] = 2*(resultDict[category]['Precision']*resultDict[category]['Recall'])\\\n",
    "                                            /(resultDict[category]['Precision'] + resultDict[category]['Recall'])\n",
    "        \n",
    "    return resultDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert bank to org in real tag\n",
    "munirahRealTagList = changeBanktoOrg(munirahList)\n",
    "\n",
    "#total number of correct prediction, prediction and entities in real result by each category\n",
    "finalMunirahList = calculateResult(pred = predMunirahList, real = munirahRealTagList, \n",
    "                                    categoryList = ['PERSON', 'ORG'])\n",
    "\n",
    "metricMunirahDict = calculateEvalMetric(finalMunirahList, categoryList = ['PERSON', 'ORG', 'NE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert bank to org in real tag\n",
    "crfRealTagList = changeBanktoOrg(crfList)\n",
    "\n",
    "#total number of correct prediction, prediction and entities in real result by each category\n",
    "finalCRFList = calculateResult(pred = predCRFList, real = crfRealTagList, \n",
    "                                    categoryList = ['PERSON', 'ORG'])\n",
    "\n",
    "# finalCRFList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>PERSON</th>\n",
       "      <th>ORG</th>\n",
       "      <th>NE</th>\n",
       "      <th>Overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fn</td>\n",
       "      <td>857.000000</td>\n",
       "      <td>1130.000000</td>\n",
       "      <td>4219.000000</td>\n",
       "      <td>6206.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fp</td>\n",
       "      <td>1914.000000</td>\n",
       "      <td>2569.000000</td>\n",
       "      <td>2854.000000</td>\n",
       "      <td>7337.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tp</td>\n",
       "      <td>309.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>2123.000000</td>\n",
       "      <td>2617.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.139001</td>\n",
       "      <td>0.067175</td>\n",
       "      <td>0.426562</td>\n",
       "      <td>0.262909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.265009</td>\n",
       "      <td>0.140684</td>\n",
       "      <td>0.334752</td>\n",
       "      <td>0.296611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>F1Score</td>\n",
       "      <td>0.182355</td>\n",
       "      <td>0.090931</td>\n",
       "      <td>0.375121</td>\n",
       "      <td>0.278745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric       PERSON          ORG           NE      Overall\n",
       "0         fn   857.000000  1130.000000  4219.000000  6206.000000\n",
       "1         fp  1914.000000  2569.000000  2854.000000  7337.000000\n",
       "2         tp   309.000000   185.000000  2123.000000  2617.000000\n",
       "3  Precision     0.139001     0.067175     0.426562     0.262909\n",
       "4     Recall     0.265009     0.140684     0.334752     0.296611\n",
       "5    F1Score     0.182355     0.090931     0.375121     0.278745"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert bank to org in real tag\n",
    "crfRealTagList = changeBanktoOrg(crfList)\n",
    "\n",
    "#total number of correct prediction, prediction and entities in real result by each category\n",
    "finalCRFList = calculateResult(pred = predCRFList, real = crfRealTagList, \n",
    "                                    categoryList = ['PERSON', 'ORG'])\n",
    "\n",
    "metricCRFDict = calculateEvalMetric(finalCRFList, categoryList = ['PERSON', 'ORG', 'NE'])\n",
    "\n",
    "dfCRF = pd.DataFrame(metricCRFDict)\n",
    "# dfCRF.columns = [i + '_CRF' for i in dfCRF.columns]\n",
    "dfCRF.reset_index(inplace = True)\n",
    "dfCRF.rename(columns = {'index':'Metric'}, inplace = True)\n",
    "filename = \"D:\\\\Users\\\\figohjs\\\\Documents\\\\NLP\\\\NER\\\\Data\\\\result\\\\2020-12-17_CRFMetrics.csv\"\n",
    "dfCRF.to_csv(filename, index = False)\n",
    "dfCRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>PERSON</th>\n",
       "      <th>ORG</th>\n",
       "      <th>NE</th>\n",
       "      <th>Overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fn</td>\n",
       "      <td>1013.000000</td>\n",
       "      <td>1076.000000</td>\n",
       "      <td>4336.000000</td>\n",
       "      <td>6425.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fp</td>\n",
       "      <td>1527.000000</td>\n",
       "      <td>2769.000000</td>\n",
       "      <td>2664.000000</td>\n",
       "      <td>6960.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tp</td>\n",
       "      <td>274.000000</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>2112.000000</td>\n",
       "      <td>2592.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.152138</td>\n",
       "      <td>0.069244</td>\n",
       "      <td>0.442211</td>\n",
       "      <td>0.271357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.212898</td>\n",
       "      <td>0.160686</td>\n",
       "      <td>0.327543</td>\n",
       "      <td>0.287457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>F1Score</td>\n",
       "      <td>0.177461</td>\n",
       "      <td>0.096782</td>\n",
       "      <td>0.376336</td>\n",
       "      <td>0.279175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric       PERSON          ORG           NE      Overall\n",
       "0         fn  1013.000000  1076.000000  4336.000000  6425.000000\n",
       "1         fp  1527.000000  2769.000000  2664.000000  6960.000000\n",
       "2         tp   274.000000   206.000000  2112.000000  2592.000000\n",
       "3  Precision     0.152138     0.069244     0.442211     0.271357\n",
       "4     Recall     0.212898     0.160686     0.327543     0.287457\n",
       "5    F1Score     0.177461     0.096782     0.376336     0.279175"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert bank to org in real tag\n",
    "crfRealTagList = changeBanktoOrg(crfList)\n",
    "\n",
    "#total number of correct prediction, prediction and entities in real result by each category\n",
    "finalCRFList = calculateResult(pred = predCRFList, real = crfRealTagList, \n",
    "                                    categoryList = ['PERSON', 'ORG'])\n",
    "\n",
    "metricCRFDict = calculateEvalMetric(finalCRFList, categoryList = ['PERSON', 'ORG', 'NE'])\n",
    "\n",
    "dfCRF = pd.DataFrame(metricCRFDict)\n",
    "# dfCRF.columns = [i + '_CRF' for i in dfCRF.columns]\n",
    "dfCRF.reset_index(inplace = True)\n",
    "dfCRF.rename(columns = {'index':'Metric'}, inplace = True)\n",
    "dfCRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>PERSON</th>\n",
       "      <th>ORG</th>\n",
       "      <th>NE</th>\n",
       "      <th>Overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fn</td>\n",
       "      <td>459.000000</td>\n",
       "      <td>1471.000000</td>\n",
       "      <td>4851.000000</td>\n",
       "      <td>6781.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fp</td>\n",
       "      <td>1912.000000</td>\n",
       "      <td>739.000000</td>\n",
       "      <td>1986.000000</td>\n",
       "      <td>4637.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tp</td>\n",
       "      <td>1089.000000</td>\n",
       "      <td>552.000000</td>\n",
       "      <td>2306.000000</td>\n",
       "      <td>3947.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.362879</td>\n",
       "      <td>0.427576</td>\n",
       "      <td>0.537279</td>\n",
       "      <td>0.459809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.703488</td>\n",
       "      <td>0.272862</td>\n",
       "      <td>0.322202</td>\n",
       "      <td>0.367916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>F1Score</td>\n",
       "      <td>0.478787</td>\n",
       "      <td>0.333132</td>\n",
       "      <td>0.402830</td>\n",
       "      <td>0.408761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric       PERSON          ORG           NE      Overall\n",
       "0         fn   459.000000  1471.000000  4851.000000  6781.000000\n",
       "1         fp  1912.000000   739.000000  1986.000000  4637.000000\n",
       "2         tp  1089.000000   552.000000  2306.000000  3947.000000\n",
       "3  Precision     0.362879     0.427576     0.537279     0.459809\n",
       "4     Recall     0.703488     0.272862     0.322202     0.367916\n",
       "5    F1Score     0.478787     0.333132     0.402830     0.408761"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfSpacy = pd.DataFrame(metricMunirahDict)\n",
    "# dfSpacy.columns = [i + '_SpaCy' for i in dfSpacy.columns]\n",
    "dfSpacy.reset_index(inplace = True)\n",
    "dfSpacy.rename(columns = {'index':'Metric'}, inplace = True)\n",
    "filename = \"D:\\\\Users\\\\figohjs\\\\Documents\\\\NLP\\\\NER\\\\Data\\\\result\\\\2020-12-17_MunirahMetrics.csv\"\n",
    "dfSpacy.to_csv(filename, index = False)\n",
    "dfSpacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TestEnv",
   "language": "python",
   "name": "testenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
