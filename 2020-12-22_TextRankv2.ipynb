{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import networkx as nx\n",
    "import math\n",
    "from timeit import default_timer as timer\n",
    "from IPython.display import display, Math, Latex\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "import itertools\n",
    "from gensim.summarization import keywords\n",
    "import enchant\n",
    "\n",
    "#british dict\n",
    "d = enchant.Dict(\"en_GB\")\n",
    "StrCol = \"ACHIEVEMENT\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = \"D:/Users/figohjs/Documents/JMIS/Data/2019_preprocessed.csv\"\n",
    "# filename = \"D:/Users/figohjs/Documents/JMIS/Data/preprocessed_bykra.csv\"\n",
    "filename = \"D:/Users/figohjs/Documents/JMIS/Data/toprocess_v1.csv\"\n",
    "\n",
    "df = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 12.3772s\n"
     ]
    }
   ],
   "source": [
    "startTime = timer()\n",
    "\n",
    "# Extract word vectors from word embedding - 100 dim\n",
    "embeddingFile = \"./Embedding/glove.6B.100d.txt\"\n",
    "\n",
    "#{'word1':embedding in (100,), 'word2':embedding in (100,)}\n",
    "word_embeddings = {}\n",
    "with open(embeddingFile, encoding='utf-8') as myFile:\n",
    "    for line in myFile:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        word_embeddings[word] = coefs\n",
    "\n",
    "#get embedding for each word for each sentence\n",
    "#get final embedding by summing all corresponding embedding - each sentence one sentence embedding (100,)\n",
    "sentence_vectors = []\n",
    "for sentence in df[StrCol].values:\n",
    "    totalWords = len(sentence.split())\n",
    "    #get average score of embedding\n",
    "    #if d sentence is not an empty string\n",
    "    if len(sentence) != 0:\n",
    "        v = sum([word_embeddings.get(word, np.zeros((100,))) for word in sentence.split()])\\\n",
    "                /(totalWords + 0.001)\n",
    "    else:\n",
    "        v = np.zeros((100,))\n",
    "    sentence_vectors.append(v)\n",
    "    \n",
    "endTime = timer()\n",
    "print(\"Total time: %0.4fs\" % (endTime - startTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text - text array\n",
    "def generateScores(text):\n",
    "    #contruct similarity matrix\n",
    "    totalNoSentences = len(text)\n",
    "    sim_mat = np.zeros([totalNoSentences, totalNoSentences])\n",
    "    indexArray = np.arange(totalNoSentences)\n",
    "    \n",
    "    for i in indexArray:\n",
    "        for j in indexArray:\n",
    "            if i != j:\n",
    "                sim_mat[i][j] = cosine_similarity(sentence_vectors[i].reshape(1,100), \n",
    "                                                  sentence_vectors[j].reshape(1,100))[0,0]\n",
    "    \n",
    "    #use pagerank algo\n",
    "    nx_graph = nx.from_numpy_array(sim_mat)\n",
    "    scores = nx.pagerank(nx_graph)\n",
    "    \n",
    "    #sort sentence based on scores\n",
    "    ranked_sentences = sorted(((scores[indexArray[no]],s) for no, s in enumerate(text)), reverse=True)\n",
    "    return ranked_sentences\n",
    "\n",
    "def getScoredSentences(textArray):\n",
    "    startTime = timer()\n",
    "    topSentenceList = []\n",
    "    for no, textList in enumerate(textArray):\n",
    "        scoreArray = generateScores(textList)   \n",
    "        topSentenceList.append(scoreArray)\n",
    "    \n",
    "    endTime = timer()\n",
    "    print(\"Total time: %0.4fs\" % (endTime - startTime))\n",
    "    \n",
    "    return topSentenceList\n",
    "\n",
    "def getTopSentence(sentenceArray, threshold):\n",
    "    resultList = []\n",
    "    for sentence in sentenceArray:\n",
    "        topN = math.ceil(len(sentence)*threshold)\n",
    "        topSentences = [i[1].strip() for i in sentence[:topN] if i[1]!='']\n",
    "        resultList.append('|'.join(topSentences))\n",
    "    return resultList\n",
    "\n",
    "def generateNGram(text, ngram = 2):\n",
    "    listOfTuples = [list(nltk.ngrams(i.split(' '), ngram)) for i in text]\n",
    "    flattenListOfTuples = list(itertools.chain(*listOfTuples))\n",
    "    textNGram = ['_'.join(i) for i in flattenListOfTuples]\n",
    "    \n",
    "    return textNGram\n",
    "\n",
    "def generateTopKeywords(textArray, n = 10):\n",
    "    resultList = []\n",
    "    for text in textArray:\n",
    "        tfidf_Vectorizer = TfidfVectorizer()\n",
    "        #dim: number of doc X number of unique terms\n",
    "        tfIdf_Text = tfidf_Vectorizer.fit_transform(text)\n",
    "\n",
    "        dfTemp = pd.DataFrame(tfIdf_Text.toarray(), columns = tfidf_Vectorizer.get_feature_names())\n",
    "        resultDict = dict(sorted(list(zip(dfTemp.columns, dfTemp.max(axis = 1))),\n",
    "                           key = lambda x:x[1], reverse = True)[:n])\n",
    "        keywordsList = list(resultDict.keys())\n",
    "        resultList.append(keywordsList)\n",
    "        \n",
    "    return resultList\n",
    "\n",
    "def generateKeywordsGensim(textArray, n = 10):\n",
    "    resultList = []\n",
    "    for text in textArray:\n",
    "        cleanText = re.sub(' +',  ' ',re.sub('\\n|\\|', ' ',str(text))).strip()\n",
    "        try:\n",
    "            words = keywords(cleanText, pos_filter = 'NN', lemmatize = True, words = n)\n",
    "        except:\n",
    "            words = keywords(cleanText, pos_filter = 'NN', lemmatize = True, words = None)\n",
    "        words = re.sub(\"\\n\", \",\", words)\n",
    "        resultList.append(words)    \n",
    "    return resultList\n",
    "\n",
    "def filterKeywordsGensim(textArray):\n",
    "    resultList = []\n",
    "    \n",
    "    for text in textArray:\n",
    "        tempList = []\n",
    "        for i in text.split(','):    \n",
    "            if i!='':\n",
    "                if len(i.split(' ')) == 1 and not d.check(i):\n",
    "                    tempList.append(i)\n",
    "                elif len(i.split(' '))>1:\n",
    "                    tempList.append(i)\n",
    "        words = ','.join(tempList)\n",
    "        resultList.append(words)\n",
    "    \n",
    "    return resultList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 140.1332s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>GROUP</th>\n",
       "      <th>ScoredSentence</th>\n",
       "      <th>TopSentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1768</td>\n",
       "      <td>ACHIEVEMENT_1</td>\n",
       "      <td>[(0.14932332329095063,  contributed staff deve...</td>\n",
       "      <td>contributed staff development continuously loo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1768</td>\n",
       "      <td>ACHIEVEMENT_2</td>\n",
       "      <td>[(0.12957036616532078,  provided scenario anal...</td>\n",
       "      <td>provided scenario analysis risks growth|resear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1768</td>\n",
       "      <td>ACHIEVEMENT_3</td>\n",
       "      <td>[(0.14932332329095063,  collaborated world ban...</td>\n",
       "      <td>collaborated world bank team come analysis pol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1768</td>\n",
       "      <td>ACHIEVEMENT_4</td>\n",
       "      <td>[(0.1748074454489123,  led preparation documen...</td>\n",
       "      <td>led preparation documents publications externa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1768</td>\n",
       "      <td>ACHIEVEMENT_5</td>\n",
       "      <td>[(0.25825011432154193,  jek business plan ddin...</td>\n",
       "      <td>jek business plan ddincharge team yeam haris|j...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID          GROUP                                     ScoredSentence  \\\n",
       "0  1768  ACHIEVEMENT_1  [(0.14932332329095063,  contributed staff deve...   \n",
       "1  1768  ACHIEVEMENT_2  [(0.12957036616532078,  provided scenario anal...   \n",
       "2  1768  ACHIEVEMENT_3  [(0.14932332329095063,  collaborated world ban...   \n",
       "3  1768  ACHIEVEMENT_4  [(0.1748074454489123,  led preparation documen...   \n",
       "4  1768  ACHIEVEMENT_5  [(0.25825011432154193,  jek business plan ddin...   \n",
       "\n",
       "                                        TopSentences  \n",
       "0  contributed staff development continuously loo...  \n",
       "1  provided scenario analysis risks growth|resear...  \n",
       "2  collaborated world bank team come analysis pol...  \n",
       "3  led preparation documents publications externa...  \n",
       "4  jek business plan ddincharge team yeam haris|j...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idList = list(set(df['ID'].values))\n",
    "textResult = [i.split('.') for i in df[StrCol].values]\n",
    "\n",
    "dfResult = pd.DataFrame()\n",
    "dfResult['ID'] = df['ID'].values\n",
    "dfResult['GROUP'] = df['GROUP'].values\n",
    "dfResult['ScoredSentence'] = getScoredSentences(textResult)\n",
    "dfResult['TopSentences'] = getTopSentence(dfResult['ScoredSentence'].values, 0.3)\n",
    "# dfResult['Sentences'] = dfResult['ScoredSentence'].map(lambda x:'\\n'.join([i[1] for i in x]))\n",
    "dfResult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '2020-12-22_ProcessedKRA.csv'\n",
    "dfResult.to_csv(filename, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "textResult = [[j.strip() if j!='' else 'nan' for j in i.split('|')] for i in dfResult['TopSentences'].values]\n",
    "# dfResult['Top10Keywords'] = generateTopKeywords(textResult)\n",
    "\n",
    "dfResult['Top15KeywordsGensim'] = generateKeywordsGensim(textResult)\n",
    "\n",
    "dfResult['TopKeywordsGensim'] = filterKeywordsGensim(dfResult['Top15KeywordsGensim'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mla requests referred preparation', '|rating sold performance',\n",
       "       '|rating sold performance', 'rating sold performance',\n",
       "       'rating sold performance', '|rating sold performance',\n",
       "       '|rating marginal performance', '|rating sold performance',\n",
       "       'rating sold performance', '|rating sold performance',\n",
       "       'reviewed aa applications within required time frame',\n",
       "       'final presentation hod november',\n",
       "       'continuing professional development',\n",
       "       'attended following training',\n",
       "       'undertake research whistleblowing ombudsman', 'management update',\n",
       "       'attended jpw transformation workshop',\n",
       "       'standardised qr will rolled end',\n",
       "       'staffdevelopment|selfdevelopment',\n",
       "       'ensured interest bank affiliates protected',\n",
       "       'negative feedback stakeholders management', 'tides', 'attended',\n",
       "       'realised capital gain rmm', 'ii|reinsreinst',\n",
       "       'staff development|selfdevelopment', '|f|faa||aif',\n",
       "       'attended mfrs budgeting courses',\n",
       "       'filing management|asset supplies management',\n",
       "       'attended||selfdevelopment', 'improved rcsa challenged process',\n",
       "       'wip thematic review yet completed',\n",
       "       'wip supervisory work just started',\n",
       "       'involved formal informal discussions',\n",
       "       'enhancing cybersecurity governance',\n",
       "       'successfully led team draft', 'fdwg oct|completed',\n",
       "       'osh|vendor management',\n",
       "       'evaluation marginal performance|achievements',\n",
       "       'collated overall draft|completed', 'completed',\n",
       "       'niva|agreement opinions|opinion|rebecca', 'nil',\n",
       "       'projects op initiated time progress', 'attend course',\n",
       "       'assisted rsa budgeting process',\n",
       "       'completed vendor performance assessment per timeline',\n",
       "       'complied security requirement', 'low finding rc audit',\n",
       "       'building construction', 'security equipment installation',\n",
       "       'equipment installation', 'operational readiness',\n",
       "       'achieved following outcome', 'achieved following outcome',\n",
       "       'three drafts completed finetuning review',\n",
       "       'deliverables achieved', 'fs|rm job review projects|jp fied',\n",
       "       'established four tpecs value rm two qeps value less rm',\n",
       "       'business consultants companies panel', 'ii|agrobank',\n",
       "       'tentative date q', 'corporate governance|product governance',\n",
       "       'surveillance|policy research', 'legal opinions completed',\n",
       "       'completed', 'workinprogress',\n",
       "       'successfully obtained togaf certification',\n",
       "       'enhancement targeted completed dec',\n",
       "       'key contributions|achievement',\n",
       "       'supervised vet following applications', 'amlcft',\n",
       "       'reconciliation st half august pending case',\n",
       "       'design thinking september',\n",
       "       'attended leadership training workshops',\n",
       "       'finalised scope outline research',\n",
       "       'finalised scope outline research', 'prepared input remc',\n",
       "       'roms sas progress', 'mutilated currency',\n",
       "       'completed following task', 'pick double entry invoices',\n",
       "       'retirement age enhancement',\n",
       "       'attended following coursestrainingforums',\n",
       "       'initiating poc bitlocker percent', 'participated suhm workshops',\n",
       "       'refer itsm tickets', '', 'attended leadership training',\n",
       "       'ongoing', 'done', 'ongoing', 'major operational issuesbreaches',\n",
       "       'attended effective intelligence gathering', 'completed',\n",
       "       'training attended', 'bankbook version development team',\n",
       "       'provided feedback comments jp consideration',\n",
       "       'qtr completed|leading perfromance',\n",
       "       'attending itilv certification oct', 'total rejection',\n",
       "       'consulted jp thematic assessment',\n",
       "       'conducted knowledge sharing speaker',\n",
       "       'successful event one resource person', 'project implemented plan',\n",
       "       'self evaluation solid performance',\n",
       "       'self evaluation leading performance',\n",
       "       'self evaluation solid performance', 'attended following training',\n",
       "       'process reviewing following',\n",
       "       'dsibscoordinationcommunicationrelated|technical advisor policiesregulations',\n",
       "       'tor creation',\n",
       "       'bi critical security incidents found|bii critical security incidents found',\n",
       "       'coached performance issues solid performers',\n",
       "       'attended following courses', 'coauthored governors statement ar',\n",
       "       'leveraged ms teams foster close collaboration various teams across projects',\n",
       "       'edited minutes drafted various departments',\n",
       "       'provided technical advisory inputs', 'work', 'libra|frtb',\n",
       "       'bigpay', 'kliff icaap'], dtype=object)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfResult.query('Top15KeywordsGensim == \"\"')['TopSentences'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '2020-12-22_ProcessedKRAwithKeywords.csv'\n",
    "dfResult.to_csv(filename, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filename = \"Data/res_forcomparison_v2.xlsx\"\n",
    "dfValidation = pd.read_excel(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['REF_ID', 'ID', 'GROUP', 'ScoredSentence', 'TopSentences',\n",
       "       'Top15KeywordsGensim', 'TopKeywordsGensim', 'KEYWORDS',\n",
       "       'KEYWORDS_ACHIEVEMENT', 'ACHIEVEMENT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfValidation.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myknp, video\n"
     ]
    }
   ],
   "source": [
    "print(dfValidation.loc[700, \"KEYWORDS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myknp akpk\n"
     ]
    }
   ],
   "source": [
    "print(dfValidation.loc[700, \"KEYWORDS_ACHIEVEMENT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fis akpk,launching video myknp,creative ideas building\n"
     ]
    }
   ],
   "source": [
    "print(dfValidation.loc[700, \"TopKeywordsGensim\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TestEnv",
   "language": "python",
   "name": "testenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
